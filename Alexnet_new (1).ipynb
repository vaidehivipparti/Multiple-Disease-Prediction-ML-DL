{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toEhWxRu_-ID",
        "outputId": "ba2c46e4-f711-40d9-c4eb-7e662ca12226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jnS-qwXAswK",
        "outputId": "4e0d0ef0-4d34-48bd-c216-c31f806a8f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted to: /content/extracted_files/\n"
          ]
        }
      ],
      "source": [
        "zip_path = '/content/drive/MyDrive/archive (2).zip'\n",
        "\n",
        "extract_path = '/content/extracted_files/'\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Files extracted to: {extract_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsvDUWkIBMya",
        "outputId": "4655132b-d6b3-4c41-bdc8-403aa2d38641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted files: ['The IQ-OTHNCCD lung cancer dataset', 'Test cases']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUJgj8wBUA8",
        "outputId": "9d60b7ae-a3ce-45d9-81cc-9fed538731db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukyWHG4oCh3G",
        "outputId": "34bc4147-4833-4148-8be5-dece6c81177e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 1097 files [00:00, 1805.21 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "\n",
        "# Path to the original dataset\n",
        "input_folder = '/content/extracted_files/The IQ-OTHNCCD lung cancer dataset/The IQ-OTHNCCD lung cancer dataset'\n",
        "\n",
        "# Path to save the split dataset\n",
        "output_folder = '/content/split_dataset'\n",
        "\n",
        "# Split the dataset into train and validation sets (80% train, 20% validation)\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(0.8, 0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yndsFtIKDA7R",
        "outputId": "564fd0ac-e499-4c71-c759-4402a78367f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install matplotlib numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u4_PewPWDejb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LumXcpB5DrtV"
      },
      "outputs": [],
      "source": [
        "# Define AlexNet model\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):  # Change num_classes to match your dataset\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.model = models.alexnet(pretrained=True)\n",
        "        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JycDwQbyDwA4",
        "outputId": "b07504c0-c616-42b2-85f2-9e7952a2f767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class names: ['Bengin cases', 'Malignant cases', 'Normal cases']\n",
            "Training set size: 876\n",
            "Validation set size: 221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define data transformations (if not already defined)\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([  # Use 'val' instead of 'valid'\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Path to the split dataset\n",
        "data_dir = '/content/split_dataset'\n",
        "\n",
        "# Load the datasets\n",
        "image_datasets = {\n",
        "    x: ImageFolder(root=f'{data_dir}/{x}', transform=data_transforms[x])\n",
        "    for x in ['train', 'val']  # Use 'val' instead of 'valid'\n",
        "}\n",
        "\n",
        "# Create data loaders\n",
        "dataloaders = {\n",
        "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=(x == 'train'), num_workers=4)\n",
        "    for x in ['train', 'val']  # Use 'val' instead of 'valid'\n",
        "}\n",
        "\n",
        "# Get dataset sizes and class names\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}  # Use 'val' instead of 'valid'\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Training set size: {dataset_sizes['train']}\")\n",
        "print(f\"Validation set size: {dataset_sizes['val']}\")  # Use 'val' instead of 'valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHw_cyneIdOi",
        "outputId": "b7f12d34-6fc5-4e5c-dd8e-fe79cfedad7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['train', 'val']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir('/content/split_dataset'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "LesrkXNHDycL",
        "outputId": "0735a5ac-eb2f-480e-f2b9-0a8ccc73b0a9"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'val'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e0056ace3230>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m image_datasets = {\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{data_dir}/{x}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use 'val' instead of 'valid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e0056ace3230>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m image_datasets = {\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{data_dir}/{x}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Use 'val' instead of 'valid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val'"
          ]
        }
      ],
      "source": [
        "# Path to the split dataset\n",
        "data_dir = '/content/split_dataset'\n",
        "\n",
        "# Load the datasets\n",
        "image_datasets = {\n",
        "    x: ImageFolder(root=f'{data_dir}/{x}', transform=data_transforms[x])\n",
        "    for x in ['train', 'val']  # Use 'val' instead of 'valid'\n",
        "}\n",
        "\n",
        "# Create data loaders\n",
        "dataloaders = {\n",
        "    x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
        "    for x in ['train', 'val']  # Use 'val' instead of 'valid'\n",
        "}\n",
        "\n",
        "# Get dataset sizes and class names\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}  # Use 'val' instead of 'valid'\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Training set size: {dataset_sizes['train']}\")\n",
        "print(f\"Validation set size: {dataset_sizes['val']}\")  # Use 'val' instead of 'valid'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdEytzlMD6R7",
        "outputId": "233acf15-755c-4a8e-f866-8f070f73f36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 139MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlexNet(num_classes=len(class_names)).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIXPt8foEKi4",
        "outputId": "9be60da1-b268-4188-d9d1-b807bad6bb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.4375 Acc: 0.8311\n",
            "val Loss: 0.3564 Acc: 0.8688\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.4691 Acc: 0.8208\n",
            "val Loss: 0.3574 Acc: 0.8914\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.3728 Acc: 0.8527\n",
            "val Loss: 0.5684 Acc: 0.7692\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.4019 Acc: 0.8322\n",
            "val Loss: 0.2562 Acc: 0.9050\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.3712 Acc: 0.8573\n",
            "val Loss: 0.2965 Acc: 0.8778\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.3975 Acc: 0.8345\n",
            "val Loss: 0.3638 Acc: 0.8552\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.3625 Acc: 0.8425\n",
            "val Loss: 0.2377 Acc: 0.8914\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.3540 Acc: 0.8482\n",
            "val Loss: 0.2738 Acc: 0.8733\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.3072 Acc: 0.8699\n",
            "val Loss: 0.2900 Acc: 0.8869\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.3817 Acc: 0.8482\n",
            "val Loss: 0.3270 Acc: 0.8778\n",
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print('Training complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHXVDaoBIGVr",
        "outputId": "5c00b9b7-901b-4618-b5c4-2320df100d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'alexnet_lung_cancer.pth'\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'alexnet_lung_cancer.pth')\n",
        "print(\"Model saved as 'alexnet_lung_cancer.pth'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiamxOUAEQMt",
        "outputId": "f315e11c-b1ed-4115-c789-d2e7c48063d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8778\n"
          ]
        }
      ],
      "source": [
        "# Load the test dataset\n",
        "test_dataset = ImageFolder(root=f'{data_dir}/val', transform=data_transforms['val'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "running_corrects = 0\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = running_corrects.double() / len(test_dataset)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "WFCA8-G3IE1p",
        "outputId": "728767da-aa3c-427a-be51-548095218373"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models, transforms\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define the AlexNet model class\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAlexNet\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the AlexNet model class\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):  # Change num_classes to match your dataset\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.model = models.alexnet(pretrained=True)\n",
        "        self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AlexNet(num_classes=3).to(device)  # Change num_classes to match your dataset\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load('alexnet_lung_cancer.pth'))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define the same transformations used during training\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the input image\n",
        "image_path = '/content/Bengin case (101) (1).jpg'  # Replace with your image path\n",
        "image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
        "\n",
        "# Preprocess the image\n",
        "input_tensor = data_transforms(image).unsqueeze(0)  # Add batch dimension\n",
        "input_tensor = input_tensor.to(device)  # Move the input tensor to the appropriate device\n",
        "\n",
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "# Map the predicted class index to the class name\n",
        "class_names = ['Benign', 'Malignant', 'Normal']  # Replace with your class names\n",
        "predicted_class_name = class_names[predicted_class.item()]\n",
        "\n",
        "print(f'Predicted class: {predicted_class_name}')\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.title(f'Predicted: {predicted_class_name}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExRDv6CZIzOd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
